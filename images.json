{
  "cocalc": {
    "system": true,
    "label": "CoCalc",
    "package": "@cocalc/compute-server",
    "package_arm64": "@cocalc/compute-server-arm64",
    "url": "https://www.npmjs.com/package/@cocalc/compute-server",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/cocalc",
    "versions": [
      {
        "version": "1.10.1",
        "tag": "latest",
        "tested": true
      },
      {
        "version": "1.10.2",
        "tag": "test",
        "tested": true
      }
    ],
    "description": "Nodejs package.  The lightweight subset of the CoCalc Javascript code needed to run cocalc directly on the compute server for supporting websocketfs mounting, terminals, and jupyter notebooks."
  },
  "proxy": {
    "system": true,
    "label": "Proxy",
    "package": "sagemathinc/proxy",
    "icon": "network-server",
    "url": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/proxy",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/proxy",
    "versions": [
      { "tag": "1.3", "tested": true },
      { "tag": "1.4", "tested": true }
    ],
    "description": "Proxy container, which is used in Kubernetes."
  },
  "filesystem": {
    "system": true,
    "label": "Filesystem",
    "package": "sagemathinc/filesystem",
    "icon": "files",
    "url": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/filesystem",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/filesystem",
    "versions": [{ "tag": "1.1", "tested": true }],
    "description": "Filesystem container."
  },
  "base": {
    "system": true,
    "label": "Base",
    "package": "sagemathinc/base",
    "icon": "plus-square",
    "url": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/base",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/base",
    "versions": [
      { "tag": "1.0", "tested": true },
      { "tag": "1.1", "tested": true }
    ],
    "description": "Base container that many others derive from."
  },
  "compute": {
    "system": true,
    "label": "Compute",
    "package": "sagemathinc/compute",
    "icon": "desktop",
    "url": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/compute",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/compute",
    "versions": [
      { "tag": "1.0", "tested": true },
      { "tag": "1.1", "tested": true },
      { "tag": "1.2", "tested": true }
    ],
    "description": "Compute container that runs the lightweight nodejs cocalc code for serving files, terminals and jupyter."
  },
  "python": {
    "priority": 10,
    "label": "Python",
    "package": "sagemathinc/python",
    "minDiskSizeGb": 10,
    "dockerSizeGb": 2,
    "gpu": false,
    "icon": "python",
    "url": "https://www.python.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/python",
    "versions": [
      {
        "tag": "3.10.12",
        "tested": true
      },
      {
        "label": "3.10.12",
        "tag": "2024-02",
        "tested": true
      }
    ],
    "description": "[Python](https://python.org) is a versatile and user-friendly programming language, known for its clear syntax and readability. It is widely used for web development, data analysis, artificial intelligence, and scientific computing."
  },
  "microk8s": {
    "label": "Kubernetes Node",
    "package": "sagemathinc/microk8s",
    "minDiskSizeGb": 30,
    "dockerSizeGb": 2,
    "gpu": false,
    "microk8s": true,
    "icon": "servers",
    "url": "https://microk8s.io/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/microk8s",
    "versions": [
      {
        "label": "2024-03.p2",
        "tag": "2024-03.p2",
        "tested": true
      }
    ],
    "description": "Run a node of a [MicroK8s](https://microk8s.io/) Kubernetes cluster. The kubectl and helm commands are configured and available to use from a terminal on the compute server.  If you [setup ssh keys](https://doc.cocalc.com/account/ssh.html) and directly ssh as root into the the compute server, you can also [create a multinode cluster](https://microk8s.io/docs/clustering)."
  },
  "jupyterhub": {
    "authToken": true,
    "disabled": false,
    "label": "JupyterHub",
    "package": "sagemathinc/jupyterhub",
    "minDiskSizeGb": 30,
    "dockerSizeGb": 2,
    "gpu": false,
    "microk8s": true,
    "icon": "jupyter",
    "url": "https://jupyter.org/hub",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/jupyterhub",
    "versions": [
      {
        "tag": "2024-03.p3",
        "tested": true
      }
    ],
    "description": "Run a [JupyterHub](https://jupyter.org/hub) server hosted by CoCalc for your research group, class, or personal work.  This is [the official Kubernetes install](https://z2jh.jupyter.org/en/stable/jupyterhub/installation.html) of JupyterHub, and can be [fully customized](https://z2jh.jupyter.org/en/stable/jupyterhub/customization.html).",
    "description-todo": "NOTE YET, due to storage class!  You can expand later from a single node Kubernetes cluster to multiple nodes for high availability and horizontal scalability."
  },
  "sagemath": {
    "priority": 8,
    "label": "SageMath",
    "package": "sagemathinc/sagemath",
    "minDiskSizeGb": 20,
    "dockerSizeGb": 9,
    "gpu": false,
    "icon": "sagemath",
    "url": "https://www.sagemath.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/sagemath",
    "versions": [
      { "tag": "10.1", "tested": true },
      { "tag": "10.2", "tested": true }
    ],
    "description": "[SageMath](https://sagemath.org) is an open-source mathematics software system, integrating numerous software packages and providing a unified interface. It is designed for advanced algebra, geometry, number theory, cryptography, and various other fields of mathematics, accessible through a Python-based language. This image does not include optional packages, so it is smaller."
  },
  "sagemathopt": {
    "priority": 7,
    "label": "SageMath + Optional Packages",
    "package": "sagemathinc/sagemathopt",
    "minDiskSizeGb": 30,
    "dockerSizeGb": 13,
    "gpu": false,
    "icon": "sagemath",
    "url": "https://www.sagemath.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/sagemath",
    "description": "[SageMath](https://sagemath.org) is an open-source mathematics software system, integrating numerous software packages and providing a unified interface. It is designed for advanced algebra, geometry, number theory, cryptography, and various other fields of mathematics, accessible through a Python-based language.  This image also includes all of the following [https://doc.sagemath.org/html/en/reference/spkg/#optional-packages](https://doc.sagemath.org/html/en/reference/spkg/#optional-packages): 4ti2 admcycles antic benzene biopython bliss buckygen coxeter3 cryptominisat csdp cunningham_tables d3js database_cremona_ellcurve database_cubic_hecke database_jones_numfield database_knotinfo database_kohel database_mutation_class database_odlyzko_zeta database_stein_watkins database_symbolic_data debugpy dot2tex dsdp e_antic ecos_python fricas frobby gap_jupyter gap_packages gitpython igraph ipympl jupyterlab kenzo kissat latte_int libnauty libogg libsemigroups lidia lrslib mathics mathics_scanner mcqd meataxe mpfrcx msolve nibabel notedown onetbb osqp_python palettable papilo pari_elldata pari_galpol pari_nftables pari_seadata perl_term_readline_gnu phitigra pint plantri pybtex pycosat pycryptosat pysingular pytest pytest_mock pytest_xdist python_build python_igraph pyx qdldl_python retrolab rubiks saclib sage_sws2rst scip scip_sdp scs singular_jupyter sirocco slabbe snappy soplex sqlalchemy symengine tdlib texlive texttable tides topcom.   NOTE: this was everything we could successfully install in Jan 2024.  On arm64, we also have to exclude the following (which all build on identically configured x86_64): cbc, glucose, latte, lidia, snappy, and tides",
    "versions": [{ "tag": "10.2", "tested": true }]
  },
  "rstats": {
    "label": "R - Studio and Jupyter",
    "package": "sagemathinc/rstats",
    "minDiskSizeGb": 10,
    "dockerSizeGb": 3,
    "gpu": false,
    "icon": "r",
    "url": "https://www.r-project.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/rstats",
    "authToken": true,
    "versions": [
      { "label": "4.3.2", "tag": "4.3.2", "tested": true },
      {
        "version": "4.3.2",
        "label": "2024-02 (R version 4.3.2)",
        "tag": "2024-02",
        "tested": true
      }
    ],
    "description": "[R](https://www.r-project.org/) is a powerful statistical computing language and environment, widely used for data analysis, statistical modeling, and visualization.   The CoCalc R compute server image includes includes (1) **Rstudio** Server and (2) the **R Jupyter kernel.**  To use RStudio, click on the displayed https link after the server starts running (Select the 'Custom Domain Name with SSL' option below to select a custom domain name avoid a security certificate warning). To use a Jupyter notebook, open a notebook in CoCalc on the compute server and select the R kernel.  _**DISCLAIMER: RSTUDIO/POSIT PBC IS IN NO WAY ASSOCIATED WITH COCALC.**"
  },
  "julia": {
    "label": "Julia",
    "package": "sagemathinc/julia",
    "minDiskSizeGb": 10,
    "gpu": false,
    "icon": "julia",
    "url": "https://julialang.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/julia",
    "versions": [
      { "label": "1.9.4", "tag": "1.9.4", "tested": true },
      { "label": "1.10.0", "tag": "1.10.0", "tested": true },
      { "label": "1.10.1", "tag": "1.10.1", "tested": true }
    ],
    "description": "[Julia](https://julialang.org/) is a high-performance programming language designed for technical computing, combining the speed of C with the ease of use of Python. It excels in numerical analysis, computational science, and data processing with its efficient syntax and ability to handle high-level mathematical operations."
  },
  "anaconda": {
    "priority": 8,
    "disabled": false,
    "label": "Anaconda",
    "package": "sagemathinc/anaconda",
    "minDiskSizeGb": 10,
    "gpu": false,
    "icon": "python",
    "url": "https://www.sagemath.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/anaconda",
    "description": "[Miniforge](https://github.com/conda-forge/miniforge) Anaconda environment with a Python Jupyter kernel, setup and ready for you to [install any package](https://conda-forge.org/packages/) using `conda install package` command in a terminal or `!conda install -y package` in a Jupyter notebook.",
    "versions": [
      { "tag": "2024-03.p3", "tested": true },
      { "tag": "2024-03-10", "tested": true }
    ]
  },
  "anaconda-gpu": {
    "priority": 15,
    "disabled": false,
    "label": "Anaconda",
    "package": "sagemathinc/anaconda",
    "minDiskSizeGb": 30,
    "gpu": true,
    "icon": "python",
    "url": "https://www.sagemath.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/anaconda",
    "description": "[Miniforge](https://github.com/conda-forge/miniforge) Anaconda environment with GPU support and a pre-installed Python Jupyter kernel, setup and ready for you to [install any package](https://conda-forge.org/packages/) using `conda install package` command in a terminal or `!conda install -y package` in a Jupyter notebook.",
    "versions": [{ "tag": "2024-03-10", "tested": true }]
  },
  "pytorch": {
    "priority": 10,
    "label": "PyTorch",
    "package": "sagemathinc/pytorch",
    "gpu": true,
    "minDiskSizeGb": 60,
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
    "icon": "pytorch",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/pytorch",
    "upstreamVersions": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags",
    "versions": [
      { "label": "2.2.0 (2023-11)", "tag": "23.11-py3", "tested": true },
      { "label": "2.2.0 (2023-12)", "tag": "23.12-py3", "tested": true },
      { "label": "2.2.0 (2024-01)", "tag": "24.01-py3", "tested": true }
    ],
    "description": "[PyTorch](https://pytorch.org/) is an open-source machine learning library, known for its flexibility and ease of use, particularly in deep learning applications. It provides a dynamic computation graph and a rich ecosystem of tools and libraries, making it a preferred choice for researchers and developers in AI."
  },
  "tensorflow": {
    "label": "Tensorflow",
    "package": "sagemathinc/tensorflow",
    "gpu": true,
    "minDiskSizeGb": 50,
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
    "icon": "tensorflow",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/tensorflow",
    "upstreamVersions": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow/tags",
    "versions": [
      { "label": "2.14.0 (2023-11)", "tag": "23.11-tf2-py3", "tested": true },
      { "label": "2.14.0 (2023-12)", "tag": "23.12-tf2-py3", "tested": true },
      { "label": "2.14.0 (2024-01)", "tag": "24.01-tf2-py3", "tested": true }
    ],
    "description": "[TensorFlow](https://www.tensorflow.org/) is an open-source machine learning framework developed by Google, widely used for building and training neural networks. Its flexible architecture allows for easy deployment of computation across various platforms, from servers to edge devices, making it suitable for a broad range of AI applications."
  },
  "colab": {
    "priority": 7,
    "label": "Google Colab",
    "package": "sagemathinc/colab",
    "minDiskSizeGb": 60,
    "gpu": true,
    "icon": "google",
    "url": "https://github.com/googlecolab",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/colab",
    "upstreamVersions": "https://console.cloud.google.com/artifacts/docker/colab-images/us/public/runtime",
    "versions": [
      {
        "label": "2023-09-21",
        "tag": "release-colab_20230921-060057_RC00",
        "tested": true
      },
      {
        "label": "2023-12-14",
        "tag": "release-colab_20231214-060137_RC00",
        "tested": true
      },
      {
        "label": "2024-02-06",
        "tag": "release-colab_20240205-060127_RC00",
        "tested": true
      }
    ],
    "description": "[Google Colab](https://colab.google/) comes preinstalled with a wide range of popular data science and machine learning libraries, such as TensorFlow, PyTorch, Matplotlib, and Pandas. It also includes support for Python and its various packages, enabling users to jump straight into coding without worrying about setup and installation."
  },
  "openwebui": {
    "label": "OpenWebUI (Ollama)",
    "package": "sagemathinc/openwebui",
    "minDiskSizeGb": 30,
    "gpu": true,
    "icon": "robot",
    "url": "https://openwebui.com/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/openwebui",
    "description": "[Open WebUI](https://github.com/open-webui/open-webui?tab=readme-ov-file#open-webui-formerly-ollama-webui-) provides a ChatGPT style UI for a vast collection of free open models, with a huge feature set.  CoCalc adds cloud hosting, one-click setup, a layer of authentication, and an optional domain name.  When you start the container the latest version of Open WebUI is installed using Docker compose, **which can take around 1 minute during which the site is not accessible**.   Only users that know the random token can create an account on your server.  After your server starts, visit the https URL of your server, and create a new admin account.  Your chats, models and documents are stored only in Docker volumes on the compute server, which are not backed up in any way or sent anywhere except to you; in particular, when you delete the compute server, all chats are completely erased.  Use a terminal on the compute server and the [docker command line](https://docs.docker.com/storage/volumes/) if you need to extract data from these volumes.",
    "authToken": true,
    "versions": [
      {
        "tag": "2024-02-18",
        "tested": true
      },
      {
        "tag": "2024-03",
        "tested": true
      }
    ],
    "jupyterKernels": false
  },
  "cuda": {
    "label": "CUDA Development Toolkit",
    "package": "sagemathinc/cuda",
    "gpu": true,
    "minDiskSizeGb": 33,
    "icon": "nvidia",
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/cuda",
    "description": "The CUDA Toolkit from NVIDIA provides everything you need to develop GPU-accelerated applications.  The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.   It enables dramatic increases in computing performance by harnessing the power of NVIDIA graphics processing units (GPUs) for a wide range of computing tasks.",
    "upstreamVersions": "https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/supported-tags.md",
    "versions": [
      { "version": "12.3.1-devel-ubuntu22.04", "tag": "12.3.1", "tested": true }
    ],
    "jupyterKernels": false
  },
  "jax": {
    "label": "JAX",
    "package": "sagemathinc/jax",
    "gpu": true,
    "minDiskSizeGb": 48,
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax",
    "icon": "times",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/jax",
    "upstreamVersions": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax/tags",
    "versions": [
      {
        "label": "0.4.17 (2023-10)",
        "tag": "23.10-py3",
        "version": "23.10-py3",
        "tested": true
      }
    ],
    "description": "[JAX](https://jax.readthedocs.io/en/latest/) is a framework for high-performance numerical computing and machine learning research. It includes Numpy-like APIs, automatic differentiation, [XLA](https://github.com/openxla/openxla-nvgpu) acceleration and simple primitives for scaling across GPUs.   [The JAX NGC Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax) comes with all dependencies included, providing an easy place to start developing applications in areas such as NLP, Computer Vision, Multimodality, physics-based simulations, reinforcement learning, drug discovery, and neural rendering."
  },
  "cocalc-docker": {
    "disabled": true,
    "label": "CoCalc - Personal Server",
    "package": "sagemathinc/cocalc-docker",
    "minDiskSizeGb": 50
  }
}
