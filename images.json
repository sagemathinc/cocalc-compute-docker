{
  "cocalc": {
    "system": true,
    "label": "CoCalc",
    "package": "@cocalc/compute-server",
    "package_arm64": "@cocalc/compute-server-arm64",
    "url": "https://www.npmjs.com/package/@cocalc/compute-server",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/cocalc",
    "versions": [
      { "label": "test", "version": "1.8.3", "tag": "test", "tested": false },
      {
        "label": "latest",
        "version": "1.8.4",
        "tag": "latest",
        "tested": true
      }
    ],
    "description": "The lightweight subset of the CoCalc Javascript code needed to run cocalc directly on the compute server for supporting websocketfs mounting, terminals, and jupyter notebooks."
  },
  "filesystem": {
    "system": true,
    "label": "Filesystem",
    "package": "sagemathinc/filesystem",
    "icon": "files",
    "url": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/filesystem",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/filesystem",
    "versions": [
      { "tag": "1.0", "tested": true },
      { "tag": "1.1", "tested": true }
    ],
    "description": "Filesystem container."
  },
  "compute": {
    "system": true,
    "label": "Compute",
    "package": "sagemathinc/compute",
    "icon": "files",
    "url": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/compute",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/compute",
    "versions": [{ "tag": "1.0", "tested": true }],
    "description": "Compute base container."
  },
  "python": {
    "priority": 10,
    "label": "Python",
    "package": "sagemathinc/python",
    "minDiskSizeGb": 10,
    "dockerSizeGb": 2,
    "gpu": false,
    "icon": "python",
    "url": "https://www.python.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/python",
    "versions": [
      {
        "tag": "3.10.12",
        "tested": true
      },
      {
        "label": "3.10.12",
        "tag": "2024-02",
        "tested": true
      }
    ],
    "description": "[Python](https://python.org) is a versatile and user-friendly programming language, known for its clear syntax and readability. It is widely used for web development, data analysis, artificial intelligence, and scientific computing."
  },
  "sagemath": {
    "priority": 8,
    "label": "SageMath",
    "package": "sagemathinc/sagemath",
    "minDiskSizeGb": 20,
    "dockerSizeGb": 9,
    "gpu": false,
    "icon": "sagemath",
    "url": "https://www.sagemath.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/sagemath",
    "versions": [
      { "tag": "10.1", "tested": true },
      { "tag": "10.2", "tested": true }
    ],
    "description": "[SageMath](https://sagemath.org) is an open-source mathematics software system, integrating numerous software packages and providing a unified interface. It is designed for advanced algebra, geometry, number theory, cryptography, and various other fields of mathematics, accessible through a Python-based language. This image does not include optional packages, so it is smaller."
  },
  "sagemathopt": {
    "priority": 7,
    "label": "SageMath + Optional Packages",
    "package": "sagemathinc/sagemathopt",
    "minDiskSizeGb": 30,
    "dockerSizeGb": 13,
    "gpu": false,
    "icon": "sagemath",
    "url": "https://www.sagemath.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/tree/main/src/sagemath",
    "description": "[SageMath](https://sagemath.org) is an open-source mathematics software system, integrating numerous software packages and providing a unified interface. It is designed for advanced algebra, geometry, number theory, cryptography, and various other fields of mathematics, accessible through a Python-based language.  This image also includes all of the following [https://doc.sagemath.org/html/en/reference/spkg/#optional-packages](https://doc.sagemath.org/html/en/reference/spkg/#optional-packages): 4ti2 admcycles antic benzene biopython bliss buckygen coxeter3 cryptominisat csdp cunningham_tables d3js database_cremona_ellcurve database_cubic_hecke database_jones_numfield database_knotinfo database_kohel database_mutation_class database_odlyzko_zeta database_stein_watkins database_symbolic_data debugpy dot2tex dsdp e_antic ecos_python fricas frobby gap_jupyter gap_packages gitpython igraph ipympl jupyterlab kenzo kissat latte_int libnauty libogg libsemigroups lidia lrslib mathics mathics_scanner mcqd meataxe mpfrcx msolve nibabel notedown onetbb osqp_python palettable papilo pari_elldata pari_galpol pari_nftables pari_seadata perl_term_readline_gnu phitigra pint plantri pybtex pycosat pycryptosat pysingular pytest pytest_mock pytest_xdist python_build python_igraph pyx qdldl_python retrolab rubiks saclib sage_sws2rst scip scip_sdp scs singular_jupyter sirocco slabbe snappy soplex sqlalchemy symengine tdlib texlive texttable tides topcom.   NOTE: this was everything we could successfully install in Jan 2024.  On arm64, we also have to exclude the following (which all build on identically configured x86_64): cbc, glucose, latte, lidia, snappy, and tides",
    "versions": [{ "tag": "10.2", "tested": true }]
  },
  "rstats": {
    "label": "R",
    "package": "sagemathinc/rstats",
    "minDiskSizeGb": 10,
    "dockerSizeGb": 3,
    "gpu": false,
    "icon": "r",
    "url": "https://www.r-project.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/rstats",
    "versions": [{ "label": "4.3.2", "tag": "4.3.2", "tested": true }],
    "description": "[R](https://www.r-project.org/) is a powerful statistical computing language and environment, widely used for data analysis, statistical modeling, and visualization. Its extensive package ecosystem and flexible scripting capabilities make it ideal for both simple and complex data exploration tasks."
  },
  "julia": {
    "label": "Julia",
    "package": "sagemathinc/julia",
    "minDiskSizeGb": 10,
    "gpu": false,
    "icon": "julia",
    "url": "https://julialang.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/julia",
    "versions": [
      { "label": "1.9.4", "tag": "1.9.4", "tested": true },
      { "label": "1.10.0", "tag": "1.10.0", "tested": true },
      { "label": "1.10.1", "tag": "1.10.1", "tested": true }
    ],
    "description": "[Julia](https://julialang.org/) is a high-performance programming language designed for technical computing, combining the speed of C with the ease of use of Python. It excels in numerical analysis, computational science, and data processing with its efficient syntax and ability to handle high-level mathematical operations."
  },
  "anaconda": {
    "disabled": true,
    "label": "Anaconda",
    "package": "sagemathinc/anaconda",
    "minDiskSizeGb": 10,
    "gpu": false,
    "icon": "python",
    "url": "https://www.sagemath.org/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/anaconda",
    "description": "Minimal Anaconda environment nicely setup and ready for you to install packages into.",
    "versions": [{ "tag": "2024-01", "tested": true }]
  },
  "pytorch": {
    "priority": 10,
    "label": "PyTorch",
    "package": "sagemathinc/pytorch",
    "gpu": true,
    "minDiskSizeGb": 49,
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch",
    "icon": "pytorch",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/pytorch",
    "upstreamVersions": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch/tags",
    "versions": [
      { "label": "2.2.0 (2023-11)", "tag": "23.11-py3", "tested": true },
      { "label": "2.2.0 (2023-12)", "tag": "23.12-py3", "tested": true },
      { "label": "2.2.0 (2024-01)", "tag": "24.01-py3", "tested": true }
    ],
    "description": "[PyTorch](https://pytorch.org/) is an open-source machine learning library, known for its flexibility and ease of use, particularly in deep learning applications. It provides a dynamic computation graph and a rich ecosystem of tools and libraries, making it a preferred choice for researchers and developers in AI."
  },
  "tensorflow": {
    "label": "Tensorflow",
    "package": "sagemathinc/tensorflow",
    "gpu": true,
    "minDiskSizeGb": 49,
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow",
    "icon": "tensorflow",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/tensorflow",
    "upstreamVersions": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/tensorflow/tags",
    "versions": [
      { "label": "2.14.0 (2023-11)", "tag": "23.11-tf2-py3", "tested": true },
      { "label": "2.14.0 (2023-12)", "tag": "23.12-tf2-py3", "tested": true },
      { "label": "2.14.0 (2024-01)", "tag": "24.01-tf2-py3", "tested": true }
    ],
    "description": "[TensorFlow](https://www.tensorflow.org/) is an open-source machine learning framework developed by Google, widely used for building and training neural networks. Its flexible architecture allows for easy deployment of computation across various platforms, from servers to edge devices, making it suitable for a broad range of AI applications."
  },
  "colab": {
    "priority": 7,
    "label": "Google Colab",
    "package": "sagemathinc/colab",
    "minDiskSizeGb": 60,
    "gpu": true,
    "icon": "google",
    "url": "https://github.com/googlecolab",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/colab",
    "upstreamVersions": "https://console.cloud.google.com/artifacts/docker/colab-images/us/public/runtime",
    "versions": [
      {
        "label": "2023-09-21",
        "tag": "release-colab_20230921-060057_RC00",
        "tested": true
      },
      {
        "label": "2023-12-14",
        "tag": "release-colab_20231214-060137_RC00",
        "tested": true
      },
      {
        "label": "2024-02-06",
        "tag": "release-colab_20240205-060127_RC00",
        "tested": true
      }
    ],
    "description": "[Google Colab](https://colab.google/) comes preinstalled with a wide range of popular data science and machine learning libraries, such as TensorFlow, PyTorch, Matplotlib, and Pandas. It also includes support for Python and its various packages, enabling users to jump straight into coding without worrying about setup and installation."
  },
  "ollama": {
    "label": "Ollama with WebUI",
    "package": "sagemathinc/ollama",
    "minDiskSizeGb": 30,
    "gpu": true,
    "icon": "robot",
    "url": "https://ollama.ai/",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/ollama",
    "description": "[Ollama](https://ollama.ai/) makes it very easy to run Llama 2, code Llama, and [hundreds of other models](https://ollama.ai/library).  Use the [web interface](https://github.com/ollama-webui/ollama-webui#readme) or call ollama from the Python API.",
    "authToken": true,
    "versions": [
      {
        "tag": "0.1.15",
        "tested": true
      },
      {
        "label": "0.1.18",
        "version": "0.1.18",
        "tag": "0.1.18b",
        "tested": true
      }
    ],
    "jupyterKernels": false
  },
  "cuda": {
    "label": "CUDA Development Toolkit",
    "package": "sagemathinc/cuda",
    "gpu": true,
    "minDiskSizeGb": 33,
    "icon": "nvidia",
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/cuda",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/cuda",
    "description": "The CUDA Toolkit from NVIDIA provides everything you need to develop GPU-accelerated applications.  The CUDA Toolkit includes GPU-accelerated libraries, a compiler, development tools and the CUDA runtime.   It enables dramatic increases in computing performance by harnessing the power of NVIDIA graphics processing units (GPUs) for a wide range of computing tasks.",
    "upstreamVersions": "https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/supported-tags.md",
    "versions": [
      { "version": "12.3.1-devel-ubuntu22.04", "tag": "12.3.1", "tested": true }
    ],
    "jupyterKernels": false
  },
  "jax": {
    "label": "JAX",
    "package": "sagemathinc/jax",
    "gpu": true,
    "minDiskSizeGb": 48,
    "url": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax",
    "icon": "times",
    "source": "https://github.com/sagemathinc/cocalc-compute-docker/blob/main/src/jax",
    "upstreamVersions": "https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax/tags",
    "versions": [
      {
        "label": "0.4.17 (2023-10)",
        "tag": "23.10-py3",
        "version": "23.10-py3",
        "tested": true
      }
    ],
    "description": "[JAX](https://jax.readthedocs.io/en/latest/) is a framework for high-performance numerical computing and machine learning research. It includes Numpy-like APIs, automatic differentiation, [XLA](https://github.com/openxla/openxla-nvgpu) acceleration and simple primitives for scaling across GPUs.   [The JAX NGC Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/jax) comes with all dependencies included, providing an easy place to start developing applications in areas such as NLP, Computer Vision, Multimodality, physics-based simulations, reinforcement learning, drug discovery, and neural rendering."
  },
  "cocalc-docker": {
    "disabled": true,
    "label": "CoCalc - Personal Server",
    "package": "sagemathinc/cocalc-docker",
    "minDiskSizeGb": 50
  }
}
